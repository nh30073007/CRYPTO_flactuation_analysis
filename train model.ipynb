{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42242c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (CSV): 7.42085722665552e-08\n",
      "Mean Squared Error (XLSX): 0.00022000770948981413\n",
      "\u001b[32mTop 10 Coins (CSV):\n",
      "Row 86919: Currency - blackcoin, Price - 0.9995359182357788\n",
      "Row 173812: Currency - diamond, Price - 0.9995359182357788\n",
      "Row 279374: Currency - golem-network-tokens, Price - 0.9995359182357788\n",
      "Row 435703: Currency - parkbyte, Price - 0.9995359182357788\n",
      "Row 575369: Currency - terracoin, Price - 0.9995359182357788\n",
      "Row 594913: Currency - trust, Price - 0.9995359182357788\n",
      "Row 602475: Currency - unbreakablecoin, Price - 0.9995359182357788\n",
      "Row 130000: Currency - civic, Price - 0.9995293021202087\n",
      "Row 133249: Currency - clubcoin, Price - 0.9995293021202087\n",
      "Row 357567: Currency - lykke, Price - 0.9995293021202087\n",
      "\u001b[32mTop 10 Coins (XLSX):\n",
      "Row 371: Name - LockChain, Price - 0.9989762902259827\n",
      "Row 724: Name - PlatinumBAR, Price - 0.9762399196624756\n",
      "Row 135: Name - Santiment Net..., Price - 0.9657490253448486\n",
      "Row 112: Name - PayPie, Price - 0.961028516292572\n",
      "Row 168: Name - WaBi, Price - 0.955320417881012\n",
      "Row 101: Name - Iconomi, Price - 0.9545359015464783\n",
      "Row 97: Name - TenX, Price - 0.950404942035675\n",
      "Row 55: Name - Dragonchain, Price - 0.9130843281745911\n",
      "Row 299: Name - Propy, Price - 0.9109268188476562\n",
      "Row 327: Name - Universal Cur..., Price - 0.9108449816703796\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST model \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# FUNCTION VOLATILITY BANDS\n",
    "def calculate_volatility_bands(df, column, window=20, factor=2):\n",
    "    rolling_std = df[column].rolling(window=window).std()\n",
    "    upper_band = df[column] + factor * rolling_std\n",
    "    lower_band = df[column] - factor * rolling_std\n",
    "    return upper_band, lower_band\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Date', 'Price']]\n",
    "df_xlsx = df_xlsx[['Price', 'Name', 'Market Cap', 'Circulating Supply', 'Volume (24hr)']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# FILL MISSING VALUES WITH MEAN\n",
    "mean = df_csv['Price'].mean()\n",
    "df_csv.fillna(mean, inplace=True)\n",
    "mean = df_xlsx['Price'].mean()\n",
    "df_xlsx.fillna(mean, inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "# NORMALIZE AND SCALE\n",
    "scaler_csv = MinMaxScaler()\n",
    "num_cols_csv = df_csv.select_dtypes(include='number').columns\n",
    "df_csv[num_cols_csv] = scaler_csv.fit_transform(df_csv[num_cols_csv])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "num_cols_xlsx = df_xlsx.select_dtypes(include='number').columns\n",
    "df_xlsx[num_cols_xlsx] = scaler_xlsx.fit_transform(df_xlsx[num_cols_xlsx])\n",
    "\n",
    "# LABEL ENCODING FOR 'Name' COLUMN\n",
    "label_encoder = LabelEncoder()\n",
    "df_xlsx['Name'] = label_encoder.fit_transform(df_xlsx['Name'])\n",
    "\n",
    "# CALCULATE VOLATILITY BANDS\n",
    "upper_band_csv, lower_band_csv = calculate_volatility_bands(df_csv, 'Price', window=20, factor=2)\n",
    "df_csv['Upper Band'] = upper_band_csv.fillna(upper_band_csv.mean())\n",
    "df_csv['Lower Band'] = lower_band_csv.fillna(lower_band_csv.mean())\n",
    "\n",
    "upper_band_xlsx, lower_band_xlsx = calculate_volatility_bands(df_xlsx, 'Price', window=20, factor=2)\n",
    "df_xlsx['Upper Band'] = upper_band_xlsx.fillna(upper_band_xlsx.mean())\n",
    "df_xlsx['Lower Band'] = lower_band_xlsx.fillna(lower_band_xlsx.mean())\n",
    "\n",
    "# PREPARE DATA FOR XGBOOST\n",
    "X_csv = df_csv.drop(['Currency', 'Date'], axis=1)\n",
    "y_csv = df_csv['Price']\n",
    "\n",
    "X_xlsx = df_xlsx.drop('Price', axis=1)\n",
    "y_xlsx = df_xlsx['Price']\n",
    "\n",
    "# TRAIN-TEST SPLIT\n",
    "X_train_csv, X_test_csv, y_train_csv, y_test_csv = train_test_split(X_csv, y_csv, test_size=0.2, random_state=42)\n",
    "X_train_xlsx, X_test_xlsx, y_train_xlsx, y_test_xlsx = train_test_split(X_xlsx, y_xlsx, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBOOST MODEL\n",
    "xgb_model_csv = xgb.XGBRegressor()\n",
    "xgb_model_csv.fit(X_train_csv, y_train_csv)\n",
    "\n",
    "xgb_model_xlsx = xgb.XGBRegressor()\n",
    "xgb_model_xlsx.fit(X_train_xlsx, y_train_xlsx)\n",
    "\n",
    "# PREDICT AND EVALUATE\n",
    "y_pred_csv = xgb_model_csv.predict(X_test_csv)\n",
    "mse_csv = np.mean((y_test_csv - y_pred_csv) ** 2)\n",
    "print(\"Mean Squared Error (CSV):\", mse_csv)\n",
    "\n",
    "y_pred_xlsx = xgb_model_xlsx.predict(X_test_xlsx)\n",
    "mse_xlsx = np.mean((y_test_xlsx - y_pred_xlsx) ** 2)\n",
    "print(\"Mean Squared Error (XLSX):\", mse_xlsx)\n",
    "\n",
    "\n",
    "# PREDICT TOP 10 COINS WITH HIGHEST PRICES (CSV)\n",
    "if 'Currency' in df_csv.columns:\n",
    "    predicted_prices_csv = xgb_model_csv.predict(X_csv)\n",
    "    df_csv['Predicted Price'] = predicted_prices_csv\n",
    "    top_10_coins_csv = df_csv.nlargest(10, 'Predicted Price')\n",
    "    print(Fore.GREEN + \"Top 10 Coins (CSV):\")\n",
    "    for index, row in top_10_coins_csv.iterrows():\n",
    "        print(f\"Row {index}: Currency - {row['Currency']}, Price - {row['Predicted Price']}\")\n",
    "else:\n",
    "    print(\"Column 'Currency' not found in the dataframe.\")\n",
    "\n",
    "# PREDICT TOP 10 COINS WITH HIGHEST PRICES (XLSX)\n",
    "predicted_prices_xlsx = xgb_model_xlsx.predict(X_xlsx)\n",
    "df_xlsx['Predicted Price'] = predicted_prices_xlsx\n",
    "top_10_coins_xlsx = df_xlsx.nlargest(10, 'Predicted Price')\n",
    "print(Fore.GREEN + \"Top 10 Coins (XLSX):\")\n",
    "for index, row in top_10_coins_xlsx.iterrows():\n",
    "    name = label_encoder.inverse_transform([int(row['Name'])])[0]\n",
    "    print(f\"Row {index}: Name - {name}, Price - {row['Predicted Price']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89129701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb034583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ef24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b4b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0206188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16815/16815 [==============================] - 189s 11ms/step - loss: 0.0020\n",
      "Epoch 2/10\n",
      "16815/16815 [==============================] - 175s 10ms/step - loss: 0.0019\n",
      "Epoch 3/10\n",
      "16815/16815 [==============================] - 186s 11ms/step - loss: 0.0019\n",
      "Epoch 4/10\n",
      "16815/16815 [==============================] - 192s 11ms/step - loss: 0.0019\n",
      "Epoch 5/10\n",
      "16815/16815 [==============================] - 187s 11ms/step - loss: 0.0019\n",
      "Epoch 6/10\n",
      "16815/16815 [==============================] - 235s 14ms/step - loss: 0.0019\n",
      "Epoch 7/10\n",
      "16815/16815 [==============================] - 199s 12ms/step - loss: 0.0019\n",
      "Epoch 8/10\n",
      "16815/16815 [==============================] - 200s 12ms/step - loss: 0.0019\n",
      "Epoch 9/10\n",
      "16815/16815 [==============================] - 183s 11ms/step - loss: 0.0019\n",
      "Epoch 10/10\n",
      "16815/16815 [==============================] - 182s 11ms/step - loss: 0.0019\n",
      "Epoch 1/10\n",
      "39/39 [==============================] - 4s 10ms/step - loss: 0.0401\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0371\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0372\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0368\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0368\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0369\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0372\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0375\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0369\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0367\n",
      "1/1 [==============================] - 1s 561ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Date: 2024-01-01 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Ripple | XLSX Price: 0.10\n",
      "Date: 2024-01-02 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Cardano | XLSX Price: 0.10\n",
      "Date: 2024-01-03 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Stellar | XLSX Price: 0.10\n",
      "Date: 2024-01-04 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: NEM | XLSX Price: 0.10\n",
      "Date: 2024-01-05 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: TRON | XLSX Price: 0.10\n",
      "Date: 2024-01-06 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Tether | XLSX Price: 0.10\n",
      "Date: 2024-01-07 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Bytecoin | XLSX Price: 0.11\n",
      "Date: 2024-01-08 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Status | XLSX Price: 0.11\n",
      "Date: 2024-01-09 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Verge | XLSX Price: 0.08\n",
      "Date: 2024-01-10 | CSV Currency: 0x | CSV Price: 0.00 | XLSX Name: Siacoin | XLSX Price: 0.08\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# FUNCTION TO CALCULATE VOLATILITY BANDS\n",
    "def calculate_volatility_bands(df, column, window=20, factor=2):\n",
    "    rolling_std = df[column].rolling(window=window).std()\n",
    "    upper_band = df[column] + factor * rolling_std\n",
    "    lower_band = df[column] - factor * rolling_std\n",
    "    return upper_band, lower_band\n",
    "\n",
    "# FUNCTION TO PREPARE DATA FOR RNN\n",
    "def prepare_rnn_data(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Price']]\n",
    "df_xlsx = df_xlsx[['Name', 'Price']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_csv.dropna(subset=['Price'], inplace=True)\n",
    "df_xlsx.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "# NORMALIZE AND SCALE\n",
    "scaler_csv = MinMaxScaler()\n",
    "df_csv[['Price']] = scaler_csv.fit_transform(df_csv[['Price']])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "df_xlsx[['Price']] = scaler_xlsx.fit_transform(df_xlsx[['Price']])\n",
    "\n",
    "# CONVERT TO SEQUENTIAL DATA FOR RNN\n",
    "window_size = 20  # Number of previous time steps to consider\n",
    "X_csv, y_csv = prepare_rnn_data(df_csv['Price'].values, window_size)\n",
    "X_xlsx, y_xlsx = prepare_rnn_data(df_xlsx['Price'].values, window_size)\n",
    "\n",
    "# BUILD RNN MODEL\n",
    "model_csv = Sequential()\n",
    "model_csv.add(LSTM(64, input_shape=(window_size, 1)))\n",
    "model_csv.add(Dense(1))\n",
    "model_csv.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_csv.fit(X_csv, y_csv, epochs=10, batch_size=32)\n",
    "\n",
    "model_xlsx = Sequential()\n",
    "model_xlsx.add(LSTM(64, input_shape=(window_size, 1)))\n",
    "model_xlsx.add(Dense(1))\n",
    "model_xlsx.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_xlsx.fit(X_xlsx, y_xlsx, epochs=10, batch_size=32)\n",
    "\n",
    "# PREDICT FUTURE PRICES\n",
    "future_dates = pd.date_range(start='2024-01-01', periods=10, freq='D')\n",
    "\n",
    "X_csv_pred = df_csv['Price'].values[-window_size:].reshape(1, window_size, 1)\n",
    "predicted_prices_csv = []\n",
    "for _ in range(10):\n",
    "    predicted_price_csv = model_csv.predict(X_csv_pred)[0][0]\n",
    "    predicted_prices_csv.append(predicted_price_csv)\n",
    "    X_csv_pred = np.append(X_csv_pred[:, 1:, :], [[[predicted_price_csv]]], axis=1)\n",
    "\n",
    "X_xlsx_pred = df_xlsx['Price'].values[-window_size:].reshape(1, window_size, 1)\n",
    "predicted_prices_xlsx = []\n",
    "for _ in range(10):\n",
    "    predicted_price_xlsx = model_xlsx.predict(X_xlsx_pred)[0][0]\n",
    "    predicted_prices_xlsx.append(predicted_price_xlsx)\n",
    "    X_xlsx_pred = np.append(X_xlsx_pred[:, 1:, :], [[[predicted_price_xlsx]]], axis=1)\n",
    "\n",
    "# INVERSE TRANSFORM PREDICTED PRICES\n",
    "predicted_prices_csv = scaler_csv.inverse_transform(np.array(predicted_prices_csv).reshape(-1, 1))\n",
    "predicted_prices_xlsx = scaler_xlsx.inverse_transform(np.array(predicted_prices_xlsx).reshape(-1, 1))\n",
    "\n",
    "# OUTPUT PREDICTED PRICES\n",
    "for date, price_csv, price_xlsx, currency, name in zip(future_dates, predicted_prices_csv, predicted_prices_xlsx, df_csv['Currency'], df_xlsx['Name']):\n",
    "    print(f\"Date: {date.strftime('%Y-%m-%d')} | CSV Currency: {currency} | CSV Price: {price_csv[0]:.2f} | XLSX Name: {name} | XLSX Price: {price_xlsx[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7feec96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
