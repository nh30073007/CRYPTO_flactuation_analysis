{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fb9717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency    0\n",
      "Date        0\n",
      "Price       0\n",
      "dtype: int64\n",
      "   Currency      Date     Price\n",
      "0        0x  0.898196  0.322431\n",
      "1        0x  0.898791  0.610335\n",
      "2        0x  0.899365  0.818997\n",
      "10       0x  0.903951  0.988497\n",
      "11       0x  0.904525  0.989645\n",
      "12       0x  0.905098  0.944861\n",
      "14       0x  0.906244  0.969461\n",
      "17       0x  0.907978  0.894430\n",
      "18       0x  0.908552  0.836691\n",
      "19       0x  0.909125  0.626589\n",
      "       Price  Market Cap  Circulating Supply  Volume (24hr)\n",
      "2   0.567405    1.000000            0.014448       1.000000\n",
      "4   0.244532    0.286437            0.009603       0.303565\n",
      "6   0.237851    0.198071            0.006827       0.084650\n",
      "10  0.333933    0.135782            0.003333       0.030048\n",
      "13  0.029423    0.087402            0.024351       0.184554\n",
      "18  0.547760    0.054868            0.000821       0.877057\n",
      "27  0.002745    0.022788            0.068148       0.002687\n",
      "28  0.140941    0.022099            0.001285       0.136280\n",
      "29  0.032382    0.021327            0.005399       0.011871\n",
      "31  0.014173    0.020731            0.011990       0.010832\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESS TASK....\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Date', 'Price']]\n",
    "df_xlsx = df_xlsx[['Price','Market Cap', 'Circulating Supply', 'Volume (24hr)']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# FILL MISSING VALUES WITH MEAN\n",
    "mean = df_csv['Price'].mean()\n",
    "df_csv.fillna(mean, inplace=True)\n",
    "mean = df_xlsx['Price'].mean()\n",
    "df_xlsx.fillna(mean, inplace=True)\n",
    "\n",
    "# FILL MISSING VALUES WITH MODE\n",
    "mode = df_csv['Price'].mode().iloc[0]\n",
    "df_csv.fillna(mode, inplace=True)\n",
    "mode = df_xlsx['Price'].mode().iloc[0]\n",
    "df_xlsx.fillna(mode, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "# NORMALIZE AND SCALING\n",
    "scaler_csv = MinMaxScaler()\n",
    "num_cols_csv = df_csv.select_dtypes(include='number').columns\n",
    "df_csv[num_cols_csv] = scaler_csv.fit_transform(df_csv[num_cols_csv])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "num_cols_xlsx = df_xlsx.select_dtypes(include='number').columns\n",
    "df_xlsx[num_cols_xlsx] = scaler_xlsx.fit_transform(df_xlsx[num_cols_xlsx])\n",
    "\n",
    "print(df_csv.head(10))\n",
    "print(df_xlsx.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a4478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146087f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency    0\n",
      "Date        0\n",
      "Price       0\n",
      "dtype: int64\n",
      "Correlation matrix for CSV dataset:\n",
      "           Date     Price\n",
      "Date   1.000000  0.190454\n",
      "Price  0.190454  1.000000\n",
      "Correlation matrix for XLSX dataset:\n",
      "                       Price  Market Cap  Circulating Supply  Volume (24hr)\n",
      "Price               1.000000    0.080074           -0.034656       0.099747\n",
      "Market Cap          0.080074    1.000000            0.010975       0.785057\n",
      "Circulating Supply -0.034656    0.010975            1.000000       0.004944\n",
      "Volume (24hr)       0.099747    0.785057            0.004944       1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nh013\\AppData\\Local\\Temp\\ipykernel_9612\\2772069407.py:63: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlation_csv = df_csv.corr()\n"
     ]
    }
   ],
   "source": [
    "#CORRELETION ANALYSIS......\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Date', 'Price']]\n",
    "df_xlsx = df_xlsx[['Price','Market Cap', 'Circulating Supply', 'Volume (24hr)']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# FILL MISSING VALUES WITH MEAN\n",
    "mean = df_csv['Price'].mean()\n",
    "df_csv.fillna(mean, inplace=True)\n",
    "mean = df_xlsx['Price'].mean()\n",
    "df_xlsx.fillna(mean, inplace=True)\n",
    "\n",
    "# FILL MISSING VALUES WITH MODE\n",
    "mode = df_csv['Price'].mode().iloc[0]\n",
    "df_csv.fillna(mode, inplace=True)\n",
    "mode = df_xlsx['Price'].mode().iloc[0]\n",
    "df_xlsx.fillna(mode, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "# NORMALIZE AND SCALING\n",
    "scaler_csv = MinMaxScaler()\n",
    "num_cols_csv = df_csv.select_dtypes(include='number').columns\n",
    "df_csv[num_cols_csv] = scaler_csv.fit_transform(df_csv[num_cols_csv])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "num_cols_xlsx = df_xlsx.select_dtypes(include='number').columns\n",
    "df_xlsx[num_cols_xlsx] = scaler_xlsx.fit_transform(df_xlsx[num_cols_xlsx])\n",
    "\n",
    "# CORRELATION ANALYSIS\n",
    "correlation_csv = df_csv.corr()\n",
    "correlation_xlsx = df_xlsx.corr()\n",
    "\n",
    "print(\"Correlation matrix for CSV dataset:\")\n",
    "print(correlation_csv)\n",
    "\n",
    "print(\"Correlation matrix for XLSX dataset:\")\n",
    "print(correlation_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f5c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee34ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency    0\n",
      "Date        0\n",
      "Price       0\n",
      "dtype: int64\n",
      "   Currency      Date     Price  Upper Band  Lower Band\n",
      "0        0x  0.898196  0.322431    0.145943    0.045604\n",
      "1        0x  0.898791  0.610335    0.145943    0.045604\n",
      "2        0x  0.899365  0.818997    0.145943    0.045604\n",
      "10       0x  0.903951  0.988497    0.145943    0.045604\n",
      "11       0x  0.904525  0.989645    0.145943    0.045604\n",
      "12       0x  0.905098  0.944861    0.145943    0.045604\n",
      "14       0x  0.906244  0.969461    0.145943    0.045604\n",
      "17       0x  0.907978  0.894430    0.145943    0.045604\n",
      "18       0x  0.908552  0.836691    0.145943    0.045604\n",
      "19       0x  0.909125  0.626589    0.145943    0.045604\n",
      "       Price      Name  Market Cap  Circulating Supply  Volume (24hr)  \\\n",
      "2   0.567405    Ripple    1.000000            0.014448       1.000000   \n",
      "4   0.244532   Cardano    0.286437            0.009603       0.303565   \n",
      "6   0.237851   Stellar    0.198071            0.006827       0.084650   \n",
      "10  0.333933       NEM    0.135782            0.003333       0.030048   \n",
      "13  0.029423      TRON    0.087402            0.024351       0.184554   \n",
      "18  0.547760    Tether    0.054868            0.000821       0.877057   \n",
      "27  0.002745  Bytecoin    0.022788            0.068148       0.002687   \n",
      "28  0.140941    Status    0.022099            0.001285       0.136280   \n",
      "29  0.032382     Verge    0.021327            0.005399       0.011871   \n",
      "31  0.014173   Siacoin    0.020731            0.011990       0.010832   \n",
      "\n",
      "    Upper Band  Lower Band  \n",
      "2     0.460975   -0.209546  \n",
      "4     0.460975   -0.209546  \n",
      "6     0.460975   -0.209546  \n",
      "10    0.460975   -0.209546  \n",
      "13    0.460975   -0.209546  \n",
      "18    0.460975   -0.209546  \n",
      "27    0.460975   -0.209546  \n",
      "28    0.460975   -0.209546  \n",
      "29    0.460975   -0.209546  \n",
      "31    0.460975   -0.209546  \n"
     ]
    }
   ],
   "source": [
    "#VOLATILITY BAND FEATURE ENGINEERING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# FUNCTION  VOLATILITY BANDS\n",
    "def calculate_volatility_bands(df, column, window=20, factor=2):\n",
    "    rolling_std = df[column].rolling(window=window).std()\n",
    "    upper_band = df[column] + factor * rolling_std\n",
    "    lower_band = df[column] - factor * rolling_std\n",
    "    return upper_band, lower_band\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Date', 'Price']]\n",
    "df_xlsx = df_xlsx[['Price','Name','Market Cap', 'Circulating Supply', 'Volume (24hr)']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# FILL MISSING VALUES WITH MEAN\n",
    "mean = df_csv['Price'].mean()\n",
    "df_csv.fillna(mean, inplace=True)\n",
    "mean = df_xlsx['Price'].mean()\n",
    "df_xlsx.fillna(mean, inplace=True)\n",
    "\n",
    "# FILL MISSING VALUES WITH MODE\n",
    "mode = df_csv['Price'].mode().iloc[0]\n",
    "df_csv.fillna(mode, inplace=True)\n",
    "mode = df_xlsx['Price'].mode().iloc[0]\n",
    "df_xlsx.fillna(mode, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "# NORMALIZE AND SCALING\n",
    "scaler_csv = MinMaxScaler()\n",
    "num_cols_csv = df_csv.select_dtypes(include='number').columns\n",
    "df_csv[num_cols_csv] = scaler_csv.fit_transform(df_csv[num_cols_csv])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "num_cols_xlsx = df_xlsx.select_dtypes(include='number').columns\n",
    "df_xlsx[num_cols_xlsx] = scaler_xlsx.fit_transform(df_xlsx[num_cols_xlsx])\n",
    "\n",
    "\n",
    "# CALCULATE VOLATILITY BANDS\n",
    "upper_band_csv, lower_band_csv = calculate_volatility_bands(df_csv, 'Price', window=20, factor=2)\n",
    "df_csv['Upper Band'] = upper_band_csv.fillna(upper_band_csv.mean())\n",
    "df_csv['Lower Band'] = lower_band_csv.fillna(lower_band_csv.mean())\n",
    "\n",
    "upper_band_xlsx, lower_band_xlsx = calculate_volatility_bands(df_xlsx, 'Price', window=20, factor=2)\n",
    "df_xlsx['Upper Band'] = upper_band_xlsx.fillna(upper_band_xlsx.mean())\n",
    "df_xlsx['Lower Band'] = lower_band_xlsx.fillna(lower_band_xlsx.mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df_csv.head(10))\n",
    "print(df_xlsx.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f2b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ffb59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency    0\n",
      "Date        0\n",
      "Price       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nh013\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Currency      Date     Price\n",
      "0        0x  0.898196  0.322431\n",
      "1        0x  0.898791  0.610335\n",
      "2        0x  0.899365  0.818997\n",
      "10       0x  0.903951  0.988497\n",
      "11       0x  0.904525  0.989645\n",
      "12       0x  0.905098  0.944861\n",
      "14       0x  0.906244  0.969461\n",
      "17       0x  0.907978  0.894430\n",
      "18       0x  0.908552  0.836691\n",
      "19       0x  0.909125  0.626589\n",
      "       Price  Market Cap  Circulating Supply  Volume (24hr)  Cluster\n",
      "2   0.567405    1.000000            0.014448       1.000000        1\n",
      "4   0.244532    0.286437            0.009603       0.303565        2\n",
      "6   0.237851    0.198071            0.006827       0.084650        2\n",
      "10  0.333933    0.135782            0.003333       0.030048        2\n",
      "13  0.029423    0.087402            0.024351       0.184554        0\n",
      "18  0.547760    0.054868            0.000821       0.877057        1\n",
      "27  0.002745    0.022788            0.068148       0.002687        0\n",
      "28  0.140941    0.022099            0.001285       0.136280        0\n",
      "29  0.032382    0.021327            0.005399       0.011871        0\n",
      "31  0.014173    0.020731            0.011990       0.010832        0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# USING K-MEANS CLUSTERING ALGORITHM\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# USING FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Date', 'Price']]\n",
    "df_xlsx = df_xlsx[['Price','Market Cap', 'Circulating Supply', 'Volume (24hr)']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# FILL MISSING VALUES WITH MEAN\n",
    "mean = df_csv['Price'].mean()\n",
    "df_csv.fillna(mean, inplace=True)\n",
    "mean = df_xlsx['Price'].mean()\n",
    "df_xlsx.fillna(mean, inplace=True)\n",
    "\n",
    "# FILL MISSING VALUES WITH MODE\n",
    "mode = df_csv['Price'].mode().iloc[0]\n",
    "df_csv.fillna(mode, inplace=True)\n",
    "mode = df_xlsx['Price'].mode().iloc[0]\n",
    "df_xlsx.fillna(mode, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "\n",
    "# NORMALIZE AND SCALING\n",
    "scaler_csv = MinMaxScaler()\n",
    "num_cols_csv = df_csv.select_dtypes(include='number').columns\n",
    "df_csv[num_cols_csv] = scaler_csv.fit_transform(df_csv[num_cols_csv])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "num_cols_xlsx = df_xlsx.select_dtypes(include='number').columns\n",
    "df_xlsx[num_cols_xlsx] = scaler_xlsx.fit_transform(df_xlsx[num_cols_xlsx])\n",
    "\n",
    "\n",
    "# CLUSTERING\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "df_clustering = df_xlsx.select_dtypes(include='number')\n",
    "kmeans.fit(df_clustering)\n",
    "labels = kmeans.labels_\n",
    "df_xlsx['Cluster'] = labels\n",
    "\n",
    "print(df_csv.head(10))\n",
    "print(df_xlsx.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b904d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98d3ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency    0\n",
      "Date        0\n",
      "Price       0\n",
      "dtype: int64\n",
      "   Currency      Date     Price\n",
      "0        0x  0.898196  0.322431\n",
      "1        0x  0.898791  0.610335\n",
      "2        0x  0.899365  0.818997\n",
      "10       0x  0.903951  0.988497\n",
      "11       0x  0.904525  0.989645\n",
      "12       0x  0.905098  0.944861\n",
      "14       0x  0.906244  0.969461\n",
      "17       0x  0.907978  0.894430\n",
      "18       0x  0.908552  0.836691\n",
      "19       0x  0.909125  0.626589\n",
      "       Price  Market Cap  Circulating Supply  Volume (24hr)  Price_Divergence  \\\n",
      "4   0.244532    0.286437            0.009603       0.303565         -0.322873   \n",
      "6   0.237851    0.198071            0.006827       0.084650         -0.006681   \n",
      "10  0.333933    0.135782            0.003333       0.030048          0.096082   \n",
      "13  0.029423    0.087402            0.024351       0.184554         -0.304510   \n",
      "18  0.547760    0.054868            0.000821       0.877057          0.518337   \n",
      "27  0.002745    0.022788            0.068148       0.002687         -0.545015   \n",
      "28  0.140941    0.022099            0.001285       0.136280          0.138196   \n",
      "29  0.032382    0.021327            0.005399       0.011871         -0.108559   \n",
      "31  0.014173    0.020731            0.011990       0.010832         -0.018209   \n",
      "32  0.147532    0.017386            0.000966       0.011332          0.133359   \n",
      "\n",
      "    Volume_Divergence  \n",
      "4           -0.696435  \n",
      "6           -0.218915  \n",
      "10          -0.054602  \n",
      "13           0.154505  \n",
      "18           0.692503  \n",
      "27          -0.874369  \n",
      "28           0.133593  \n",
      "29          -0.124409  \n",
      "31          -0.001039  \n",
      "32           0.000500  \n"
     ]
    }
   ],
   "source": [
    "#USING PRICE AND VOLUME DIVERGENCE\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Function to handle outliers\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_csv = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\Cryptocurrency Prices by Date.csv\")\n",
    "df_xlsx = pd.read_excel(r\"C:\\Users\\nh013\\Desktop\\Crypto fluctuation of 3 consecutive years\\All Currencies Table.xlsx\")\n",
    "\n",
    "# SELECT COLUMNS\n",
    "df_csv = df_csv[['Currency', 'Date', 'Price']]\n",
    "df_xlsx = df_xlsx[['Price','Market Cap', 'Circulating Supply', 'Volume (24hr)']]\n",
    "\n",
    "# IDENTIFY MISSING VALUES\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_csv.dropna(inplace=True)\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "# CONVERT 'Price' COLUMN TO NUMERIC\n",
    "df_csv['Price'] = pd.to_numeric(df_csv['Price'], errors='coerce')\n",
    "df_xlsx['Price'] = pd.to_numeric(df_xlsx['Price'], errors='coerce')\n",
    "\n",
    "# FILL MISSING VALUES WITH MEAN\n",
    "mean = df_csv['Price'].mean()\n",
    "df_csv.fillna(mean, inplace=True)\n",
    "mean = df_xlsx['Price'].mean()\n",
    "df_xlsx.fillna(mean, inplace=True)\n",
    "\n",
    "# FILL MISSING VALUES WITH MODE\n",
    "mode = df_csv['Price'].mode().iloc[0]\n",
    "df_csv.fillna(mode, inplace=True)\n",
    "mode = df_xlsx['Price'].mode().iloc[0]\n",
    "df_xlsx.fillna(mode, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_csv = handle_outliers(df_csv, 'Price')\n",
    "df_xlsx = handle_outliers(df_xlsx, 'Price')\n",
    "\n",
    "# NORMALIZE AND SCALING\n",
    "scaler_csv = MinMaxScaler()\n",
    "num_cols_csv = df_csv.select_dtypes(include='number').columns\n",
    "df_csv[num_cols_csv] = scaler_csv.fit_transform(df_csv[num_cols_csv])\n",
    "\n",
    "scaler_xlsx = MinMaxScaler()\n",
    "num_cols_xlsx = df_xlsx.select_dtypes(include='number').columns\n",
    "df_xlsx[num_cols_xlsx] = scaler_xlsx.fit_transform(df_xlsx[num_cols_xlsx])\n",
    "\n",
    "\n",
    "# PRICE AND VOLUME  DIVERGENCE\n",
    "df_xlsx['Price_Divergence'] = df_xlsx['Price'] - df_xlsx['Price'].shift(1)\n",
    "df_xlsx['Volume_Divergence'] = df_xlsx['Volume (24hr)'] - df_xlsx['Volume (24hr)'].shift(1)\n",
    "\n",
    "df_xlsx.dropna(inplace=True)\n",
    "\n",
    "\n",
    "print(df_csv.head(10))\n",
    "print(df_xlsx.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89300daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
